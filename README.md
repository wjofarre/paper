Liam O’Farrell
GA – DAT7
Identifying Crime features
Introduction
In several cities in the United States there has been a concerted effort to organize local criminal activity into meaningful data. For the most part, it has been used as a measure total criminal activity and as a law enforcement performance evaluation tool.  Although the data is useful for these purposes it also contains many features that, if identified, could be used to predict criminal activity. If law enforcement can identify what features have the greatest effect on crime they could better allocate their resources at their disposal to reduce it. 
	For a long time the metric by which crime reduction was measured was the total number of arrests made. This is not necessarily the best metric to determine crime rates, as it does not take into account the rate at which crimes are being committed. It would be more accurate to measure crime by the total number of occurrences and then measure crime reduction effectiveness based on the probability of apprehension, total crimes reported and deterrence rate. This project will only focus on the total number of crimes reported as the response variables with other factors such as weather, neighborhood, distance from a police station, resources and perhaps several others as the features.

Data
	The main data set used in this project is crime data from Chicago, IL USA. It was taken from their online open source data website. It contains all the crimes reported starting in 2007 and through 2015. The data contains information about each crime including location, GPS coordinates, neighborhood, type of crime, time of day, date, whether or not an arrest was made and several other pieces of information. Another data set used is from the Chicago Police Department that contains information about the police stations including the GPS coordinates, address and neighborhood it is in. (Data that still remains to be gathered is the city budget for each year for the city police, the total number of officers and the resources available to them)

Data Cleaning
	The collected data had a lot of missing values in its raw form especially in the earlier years. There are many reasons this might have been the case. For example, when a crime is reported often times the victim cannot recall exactly what occurred and may forget what kind of weapon the assailant used (if at all). Because of the massive amount of missing data from the earlier years, the data had been trimmed to only include crime from 2011 and onward as that is when it starts to get more complete.
	The rows with the remaining missing values where dropped from the analysis. The reasons for this being that the data set is very large so dropping incomplete data should not affect the results to dramatically. Additionally it would be difficult to predict what an appropriate placeholder for these values would be and attempting to do so could alter the results if included in the analysis. 

Approach
	The first thing I did for this project is calculate the distance from each reported to the nearest police station using the GPS coordinates from the crime data and the GPS coordinates from the police station addresses. To do this I created a for loop cross checking each crime location with station location and used the Haversine closest distance formula to calculate the difference between the GPS coordinates. Once I had a list of distances for each crime to the nearest police station I added the distance to the data frame to examine as a feature variable. The thought was that the farther away from a police station a crime occurred the less likely there would be an arrest made. After running a logistic regression on distance and arrest made I found that distance is slightly negatively correlated with the probability of apprehension. Meaning that the farther away from a police station a crime occurs the more likely an arrest is going to be made. Below is a graph of this logistic regression. The red line is the regression line and it clearly shows a weak positive correlation with distance and the probability that an arrest will occur. 
 
	The box plots also illustrate this point. The right plot is yes and the left one is no.
 
Upon further data exploration, I found that crime rates drastically increase during the summer months. There are several reasons this might be the case. The most interesting features that does have a significant effect is students being released from school. During the school year kids are occupied and have a place to go for most of the day but during the summer schools are closed and for some reason that causes crime rates to increase. It is hard to say is it the increasing temperature or children getting out of school that causes the spike in crime rates. Looking at the value counts I would hypothesize that children being released from school is the more likely indicator as the months of August and Septbember have fewer incidents and they are traditionally hotter months.


Crime Counts by Month
 
An interesting thing to analyze might be the relationship between areas with after school programs and crime rates. If students being in school is related to crime rates perhaps keeping students in school longer would have an impact on these statistics. It could be that the warmer weather causes crime rates to increase but if we find that areas with after schools programs have lower crime rates that would be an interesting finding.

Regression Models
	With the realization that using the probability of arrest might not be the best measure of city security I tried to analyze the problem using a regression approach with the total number of crimes being the dependent variable. I only had a chance to use a linear regression model for this project (in addition to the logistic regression I used when the probability of arrest response variable). I tried using a decision tree using the same inputs as I did in the linear regression but I’m not sure how accurate it was given the inputs I used and the amount of dummy variables I included in the linear regression. If I had more time I would use a more organized decision tree and maybe some ensembling techniques.
Deciding what inputs to use in the regression was challenging. Initially, I tried using a multitude of variables just to see which ones worked best and what effect they had. Because the linear model runs relatively fast this was easy to do. Ultimately the features I decided to include were budget and dummy variables for summer months and here is the regression analysis that was returned.

 
Next Steps
	The next steps are much the same as before. I would like to gather information on after school programs and city education budget and how it is distributed among neighborhoods. This data has been difficult to find and to filter so I was not able to incorporate it into this round of analysis. I would also like to use some other forms of regression models. I tried a few regression trees but they did not give me very pretty results so I did not include them in my write up. Ideally what the deliverable will be would be recommendations for the city of Chicago as to how to reduce their crime rates. Policy makers would like dials to turn that display how increasing or decreasing one factor and see the effect it has on another. Unfortunately I could not quite get to this point as I cannot conclude anything with a reasonable degree of certainty based 



